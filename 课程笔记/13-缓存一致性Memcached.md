# MemcacheD

## 1. MemcacheD系统概述

为了在保证数据持久性存储的同时，能够加快读写速度，在维护数据库服务器（数据存储在硬盘中）的同时，还设置了memcache服务器（将数据存储在RAM中，尤其是热门数据）。读写指令会先发往Mmemcache务器，如果mememcache器的内存中有该数据则直接读写，如果没有命中则继续访问数据库服务器。

该方案将读写速度提升了十倍，架构如下所示：

![](E:\研究生\其它事务\分布式系统\课程笔记\images\2023-01-20-14-55-43-20230120145525.png)

look aside和look through的区别：

- look aside模式中，缓存服务器和数据库服务器之间没有交流，缓存服务器并不知道数据库的存储，整个流程是以前端服务器为核心进行的：
  
  <img src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-20-15-40-09-20230120153716.png" title="" alt="" width="533">
  
  memcache就是采用了look aside模式。

- look through模式中，缓存服务器和数据库服务器是有交流的，整个流程是以缓存服务器为核心，前端服务器的读写指令在缓存服务器中miss后，缓存服务器会进一步向数据库服务器发起请求。

## 2. MemcacheD的具体实现

### 2.1 多副本

实际上整个服务架构中，有多个数据中心部署在不同地区，每个数据中心都包含自己的前端、memcache、数据库服务器，它们的数据库服务器中的数据都是一致的。

每个客户端一般都会访问距离自己最近的数据中心，当发生写入操作时，master数据中心完成写入操作后，会同步到其它节点上，如下图所示：

<img title="" src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-20-16-38-23-20230120162236.png" alt="" width="378" data-align="center">

### 2.2 读写流程

<img title="" src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-20-17-13-13-20230120153716.png" alt="" width="533" data-align="center">

- 读操作：
  
  1. 前端发送读指令给memcache；
  
  2. 如果memcache有，则直接返回该数据；
  
  3. 如果memcache没有，则前端继续访问数据库获取数据。

- 写操作：
  
  1. 前端发送写指令给数据库，数据库完成修改；
  
  2. 前端发送指令删除memcache上面的旧版本数据（实际上数据库服务器接到前端修改指令时，也会要求memcache删除对应数据，例如master数据中心同步所有数据中心的数据库时，memcache也会删除对应数据，不需要前端指令）。

为什么写操作会要求删除memcache上的旧数据呢？因为如果写入数据库后再读取这个数据，mmemcache返回旧数据，导致读取的数据版本错误。这就是memcache使用delete而非update的原因。

### 2.3 提高性能

对于存储系统来说，提高性能主要有两种方案：

- **分区**。通过将一大块数据分片存储到不同服务器上的方案，可以实现数据的并行读写，提高了处理效率。但分区的缺点是，对于一些非常热门的数据，每个前端都需要和几个固定的服务器频繁通信，降低了效率。

- **复制**。通过建立数据副本，可以分摊读写的压力，提高效率，而且每个前端都只需要和一个memcache服务器通信，网络压力小。但它的缺点是，同样的硬件数量下，复制方案比分区方案存储的数据要少。

为了提升性能，服务架构既采用了分区，也采用了复制。具体方案如下：

- **建立多个数据中心**。每个数据中心都有自己的前端、memcache、数据库服务器。
  
  其中所有数据中心的数据库服务器的内容是完全同步的，也就是所谓复制方案。读操作一般选择本地的数据中心，写操作是写入master数据中心，然后同步到其它数据中心。该操作大大降低了读操作的网络延迟；

- **每个数据中心内部划分多个集群**。每个数据中心内部只有一个集群，现在数据中心内部有多个集群，每个集群内部有多个前端服务器和memcache服务器，集群内的mmemcache务器分片存储数据，**这些集群之间的mememcache本关系**。前端服务器只会访问本集群内的memmemcache。
  
  多集群方案的优点是，由于memcache分片存储数据，每个前端服务器都需要和大量mmemcache务器通信。如果采用单个集群，则集群内的mememcache非常庞大，集群内部形成N^2个通信连接，这需要花费大量开销去维持这些TCP连接。拆分成多个集群后，这些通信连接数量会大大减少。**总的来说，就是分片数量要合理，不能让单个集群过大。**
  
  另外，两个集群的memcache之间是副本关系，这就可以同时处理多个前端的请求，但是对于一些不热门的数据，为它们设置太多副本对性能没有太大提升，因此它们再数据中心被单独放在一个mmemcache中，称为regional pool，也就是说冷门数据只需要保存一份副本即可。所有集群中的前端服务器都可以访问这些mememcache器。
  
  数据中心（region）的整体架构如下所示：
  
  <img title="" src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-21-15-22-47-20230121152212.png" alt="" width="499" data-align="center">

### 2.4 冷启动问题（cold start）

当数据中心启动一个全新的集群时，由于集群内的memcache服务器内存中没有存储任何数据，此时前端服务器的命中率为0，因此会继续向底层的数据库服务器发送请求，假设有两个集群，一新一旧，新集群冷启动时数据库原来1%的请求率会被提升至50%，压力会暴增，这被称为新集群的冷启动问题。

为了解决这个问题，**当新集群的前端服务器访问本地集群的memcache未命中时，会先去旧集群请求数据，得到数据后再更新本地集群的mmemcache务器**，如果依然未命中才会去访问数据库服务器。该操作使得冷启动对数据库的压力大大减轻，这个冷启动过程会持续一到两个小时，直到本地mememcache器命中率足够高。

### 2.5 惊群效应

对于热门数据来说，会同时有许多前端服务器对memcache服务器访问它。当有一个前端服务器要修改热门数据时，会发送消息让数据库修改它，同时让memcache删除它。此时其它要读取这数据的前端服务器在memcache没有命中该数据，会继续向数据库发起访问，此时就会给数据库带来较大的压力。这个问题称为惊群效应，如下图所示：

<img title="" src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-21-15-43-01-20230121154224.png" alt="" width="475" data-align="center">

对于这个问题，**memcache会给其中一个前端服务器发一个lease，并让其它前端等待**，拿到lease的那个前端服务器会去数据库拿到数据并更新memcache，让所有前端来读取。如果拿到lease的前端没有拿到数据，则lease过期后，memcache会重新选定一个前端服务器执行这个任务。

### 2.6 memcache服务器故障问题

当memcache发生故障时，如果前端访问数据库，则数据库需要承受memcache服务器丢下的每秒上百万次请求。因此MemcacheD系统会安排一台新的memcache服务器接手，但是让新服务器接手依然需要一段时间。

**在这个过渡期，系统设置了gutter server作为memcache服务器的副本**，gutter server会与memcache保持同步，用于memcache服务器故障后的临时服务。

### 2.7 一致性问题

look aside机制的delete对一致性有保护作用，但是它依然存在一致性问题。示例如下：

<img title="" src="file:///E:/研究生/其它事务/分布式系统/课程笔记/images/2023-01-21-16-56-07-20230121164410.png" alt="" width="548" data-align="center">

假设前端C1发起读请求，没有命中后从数据库读取到V1，C2发起写V2请求并成功完成，此时由于C1执行速度慢，导致C2完成后，C1才将数据V1更新到memcache，因此导致了一致性错误。

对于这问题，每当前端没有命中memcache时，系统会给该前端服务器颁发lease，只有持有该lease才能用数据库的读取结果更新memcache的数据。如果读前端一直没有更新，而新的写事务数据已经更新了memcache，那么前面颁发的lease都会失效，就不能再写入了。

因此，C2已经完成写事务后，C1的lease已经失效，因此不会将memcache的数据改为V1。
