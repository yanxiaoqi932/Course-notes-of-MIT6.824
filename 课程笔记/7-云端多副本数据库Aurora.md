# 云端多副本数据库Aurora

论文解读链接：[Aurora论文理解 - 简书](https://www.jianshu.com/p/dd6aa53c3af5)

## 1. Aurora历史

最早的时候，Amazon提供的云产品是EC2，它可以帮助用户在Amazon的机房里和Amazon的硬件上创建类似网站的应用。整个架构如下所示：

<img title="" src="https://906337931-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MAkokVMtbC7djI1pgSw%2F-MF_T54ckKwpNaGvQR0k%2F-MFcD1dhtcmrbU2fJ7uo%2Fimage.png?alt=media&token=ba3cca72-2e92-4aa4-bac0-3c08008d57f0" alt="" data-align="center" width="390">

在一台服务器上运行着VMM，VMM管理着多个EC2实例，实例中是一个完整的操作系统，在操作系统之上运行的是应用程序，例如Web服务、数据库。

WEB的EC2实例需要用到后台数据库，因此有一个数据库的EC2实例；

数据库需要硬盘存储，因此出现了EBS来提供容错多副本的两个服务器作为硬盘系统，当数据库执行写磁盘操作时，数据会通过网络送到EBS服务器。

但是EBS存在一些问题：

- EBS不是用来共享的服务。任何时候，每个EBS volume只能被一个EC2实例所使用；

- 如果你在EBS上运行一个数据库，那么最终会有大量的数据通过网络来传递，因为数据库对硬盘的所有读写都需要通过网络；

- EBS的容错性不是很好。因为EBS使用的有一致性算法是Chain Replication（链复制），所以为了降低网络开销，两个互为副本的EBS服务器处于同一个数据中心（AZ）。

## 2. 关系型数据库 Amazon RDS

RDS是第一次尝试将数据库在多个AZ之间做复制，这样就算整个数据中心挂了，你还是可以从另一个AZ重新获得数据而不丢失任何写操作。

每一次数据库软件执行一个写操作，Amazon会自动的，对数据库无感知的，将写操作拷贝发送到另一个数据中心的AZ中。从论文的图2来看，可以发现这是另一个EC2实例，它的工作就是执行与主数据库相同的操作。所以，AZ2的副数据库会将这些写操作拷贝AZ2对应的EBS服务器。

<img title="" src="https://906337931-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MAkokVMtbC7djI1pgSw%2F-MFd2WzNRICw5s2CvIg1%2F-MFdbCpVtfDvpyNjYO4H%2Fimage.png?alt=media&token=9cdf4e66-0cc4-46c5-94a3-8aac24d15a30" alt="" width="381" data-align="center">

RDS这种架构提供了更好的容错性。即使AZ1发生火灾都烧掉了，你可以在AZ2的一个新的实例中继续运行数据库，而不丢失任何数据。

但是，RDS的写操作代价极高，因为需要写大量的数据。即使如之前的例子，执行类似于 x+10，y-10，这样的操作，**虽然看起来就是修改两个整数，每个整数或许只有8字节或者16字节，但是对于data page的读写，极有可能会比10多个字节大得多。因为每一个page会有8k字节，或者16k字节，所以每次写操作都要等待四个服务器都完成8kb的数据传输写入才行**。这意味着，哪怕是只写入这两个数字，当需要更新data page时，需要向磁盘写入多得多的数据。如果使用本地的磁盘，明显会快得多。

## 3. Aurora基本概念

Aurora主要做了两个大的改进：

- 第一个是，在替代EBS的位置，有6个数据的副本，位于3个AZ，每个AZ有2个副本。所以现在有了超级容错性，并且每个写请求都需要以某种方式发送给这6个副本。
  
  ![](https://906337931-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MAkokVMtbC7djI1pgSw%2F-MFeE3STWpE-N_S7hrlX%2F-MFePvsiy7BTHzraaR4e%2Fimage.png?alt=media&token=5a197363-3b5b-4653-90cf-3f229d54d40d)
  
  **这里通过网络传递的数据只有Log条目，这才是Aurora成功的关键。每一条Log条目只有几十个字节那么多，也就是存一下旧的数值，新的数值，所以Log条目非常小**，尤其是相对于RDS中传递的巨大的data page而言。

- 第二个是，Aurora并不需要6个副本都确认了写入才能继续执行操作。相应的，只要Quorum（看第4节）形成了，也就是任意4个副本确认写入了，数据库就可以继续执行操作。
  
  所以，当我们想要执行写入操作时，如果有一个AZ下线了，或者AZ的网络连接/相应太慢了，Aurora可以忽略最慢的两个服务器，它只需要6个服务器中的任意4个确认写入，就可以继续执行。**通过这种方法，Aurora可以有更多的副本，更多的AZ，但是又不用付出大的性能代价**，因为它永远也不用等待所有的副本，只需要等待6个服务器中最快的4个服务器即可。

## 4. Quorum 复制机制

Aurora使用了Quorum这种思想，假设有N个副本：

- 为了能够执行写请求，必须要确保写操作被W个副本确认，W小于N；

- 如果要执行读请求，那么至少需要从R个副本得到所读取的信息。

这里的W对应的数字称为Write Quorum，R对应的数字称为Read Quorum，这是一个典型的Quorum配置。

当你执行写请求时，你会将新的数值和对应的版本号给所有N个服务器，但是只会等待W个服务器确认；类似的，对于读请求，你可以将读请求发送给所有的服务器，但是只等待R个服务器返回结果。

这里的关键点在于，W、R、N之间的关联。Quorum系统要求，任意你要发送写请求的W个服务器，必须与任意接收读请求的R个服务器有重叠。**这意味着，R加上W必须大于N（ 至少满足R + W = N + 1 ），这样任意W个服务器至少与任意R个服务器有一个重合。** 

这意味着，任何读请求都至少会包含一个看到了之前写请求的服务器，**由于每写入一次服务器的版本号就会增加，那么读请求获得的版本号最大的那个服务器的数据就是最新的数据。**

最后，**Quorum 复制机制可以调整读写的性能**。例如当前一共三个副本，我们可以假设W=3，每一个写请求必须被所有的3个服务器所确认。这样的话，R可以只是1。这样读请求会快得多，因为它只需要等待一个服务器的结果，但是代价是写请求执行的比较慢。

**Raft可以认为是一种强Quorum的实现，它的读写都需要通过leader。** 

## 5. Aurora读写存储服务器

注意区分一下数据库服务器和存储服务器，数据库服务器处理各种读写，而存储服务器可以视为硬盘。

- 写存储服务器
  
  **数据库服务器写入存储服务器的是Log条目。** Aurora使用Quorum只是在数据库执行事务并发出新的Log记录时，确保Log记录至少追加在4个存储服务器中，之后才能提交事务，将写请求视为完成。
  
  对于数据库服务器来说，当一个新的写请求到达时，这个写请求只是一个Log条目，Log条目中的内容需要应用到相关的page中。**但是我们不必立即执行这个更新，可以等到数据库服务器或者恢复软件想要查看那个page时才执行。** 
  
  这里的Log列表从上次page更新过之后开始（相当于page是snapshot，snapshot后面再有一系列记录更新的Log）。如果没有其他事情发生，那么存储服务器会缓存旧的page和对应的一系列Log条目。

- 读存储服务器
  
  **数据库服务器从读取存储服务器的是page。** 如果数据库服务器将自身缓存的page删除了，过了一会又需要为一个新的事务读取这个page，它会发出一个读请求。请求发送到存储服务器，会要求存储服务器返回当前最新的page数据。
  
  在这个时候，存储服务器才会将Log条目中的新数据更新到page，并将page写入到自己的磁盘中，之后再将更新了的page返回给数据库服务器。同时，存储服务器在自身cache中会删除page对应的Log列表，并更新cache中的page。

## 6. 数据分片

### 6.1 基本概念

为了能支持超过10TB数据的大型数据库，Amazon的做法是将数据库的数据，分割存储到多组存储服务器上，每一组都是6个副本，分割出来的每一份数据是10GB。

**所以，如果一个数据库需要20GB的数据，那么这个数据库会使用2个PG（Protection Group），其中一半的10GB数据在一个PG中，包含了6个存储服务器作为副本，另一半的10GB数据存储在另一个PG中，这个PG可能包含了不同的6个存储服务器作为副本。**

### 6.2 数据分片下的Log处理

数据分片后，当Aurora需要发送一个Log条目时，它会查看Log所修改的数据，并找到存储了这个数据的Protection Group，并把Log条目只发送给这个Protection Group对应的6个存储服务器。这意味着，每个Protection Group只存储了部分data page和所有与这些data page关联的Log条目。

### 6.3 数据分片下的故障恢复

所以我们想要在一个副本挂了以后，尽可能快的生成一个新的副本。表面上看，每个存储服务器存放了某个数据库的某个某个Protection Group对应的10GB数据，但实际上每个存储服务器上面存储了属于数百个Aurora实例的10GB数据块。

所以在存储服务器上，可能总共会有10TB的数据，当它故障时，需要恢复存储在原来服务器上的整个10TB的数据，对旧的副本存储器来说，通过它一个存储服务器的网络传递10TB数据是十分巨大的。

Aurora实际使用的策略是，对于一个特定的存储服务器，它存储了许多Protection Group对应的10GB的数据块，可能10TB的数据，一共存储了100个Protection Group的10GB数据块。这种模式下，如果一个存储服务器挂了，**假设上面有100个数据块，现在的替换策略是：找到100个不同的存储服务器，其中的每一个会被分配一个数据块，每一个存储服务器只需要负责恢复10GB的数据（假设有足够多的服务器，这里的服务器大概率不会有重合），这样效率就加快了100倍。**

## 7. 只读数据库（Read-only Database）

Aurora有主数据库服务器用于读写，另外还有一些只读数据库用于读，以此来提高读取数据的性能。

- 基本概念
  
  **对于写请求，可以只发送给一个数据库，因为对于后端的分布式存储服务器来说，只能支持一个写入者。** 背后的原因是，Log需要按照数字编号，如果只在一个数据库处理写请求，非常容易对Log进行编号，但是如果有多个数据库以非协同的方式处理写请求，那么为Log编号将会非常非常难。
  
  **但是对于读请求，可以发送给多个数据库。** 除了主数据库用来处理写请求，同时也有一组只读数据库。论文中宣称可以支持最多15个只读数据库。如果有大量的读请求，读请求可以分担到这些只读数据库上。

- 只读数据库的缓存更新
  
  **只读数据库也需要更新自身的缓存，主数据库会向这些只读数据库发送所有的Log条目，只读数据库用这些Log来更新它们缓存的page数据**，进而获得数据库中最新的事务处理结果。
  
  这意味着只读数据库会落后主数据库一点，但是对于大部分的只读请求来说，这没问题。因为如果你查看一个网页，如果数据落后了20毫秒，通常来说不会是一个大问题。
  
  这里一个问题是，我们不想要这个只读数据库看到未commit的事务。所以，在主数据库发给只读数据库的Log流中，主数据库需要指出，哪些事务commit了，**而只读数据库需要小心的不要应用未commit的事务到自己的缓存中，它们需要等到事务commit了再应用对应的Log**。

## 8. 总结

- 一件可以学到的事情其实比较通用，并不局限于这篇论文。大家都应该知道事务型数据库是如何工作的，并且知道事务型数据库与后端存储之间交互带来的影响。这里涉及了性能，故障修复，以及运行一个数据库的复杂度，这些问题在系统设计中会反复出现。

- 另一个件可以学到的事情是，Quorum思想。通过读写Quorum的重合，可以确保总是能看见最新的数据，但是又具备容错性。这种思想在Raft中也有体现，Raft可以认为是一种强Quorum的实现（读写操作都要过半服务器认可）。

- 这个论文中另一个有趣的想法是，数据库和存储系统基本是一起开发出来的，数据库和存储系统以一种有趣的方式集成在了一起。通常我们设计系统时，需要有好的隔离解耦来区分上层服务和底层的基础架构。但是在Aurora面临的问题中，性能问题是非常严重的，它不得不通过模糊服务和底层基础架构的边界来获得35倍的性能提升，这是个巨大的成功。

- 最后一件有意思的事情是，论文中的一些有关云基础架构中什么更重要的隐含信息。例如：
  
  - 需要担心整个AZ会出现故障；
  - 需要担心短暂的慢副本，这是经常会出现的问题；
  - 网络是主要的瓶颈，毕竟Aurora通过网络发送的是极短的数据，但是相应的，存储服务器需要做更多的工作（应用Log），从Amazon看来，网络容量相比CPU要重要的多。
